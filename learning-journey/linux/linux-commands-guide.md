# Essential Linux Commands: A DevOps Engineer's Guide to System Mastery

*As a DevOps engineer you'll find that mastering these fundamental Linux commands is crucial for efficient system administration and automation. Let's look into some of the  most important command categories that every system administrator and DevOps professional should know.*

## 1. File System Management 

The foundation of Linux system administration starts with file management. Here are the essential commands:

- `ls`: Lists directory contents, showing files and subdirectories
- `mkdir [dir]`: Creates a new directory with the specified name
- `rm -r [dir]`: Recursively removes directories and their contents
- `cp [src] [dest]`: Copies files or directories from source to destination
- `mv [src] [dest]`: Moves or renames files and directories
- `find`: Searches for files and directories based on various criteria

## 2. Text Processing & Manipulation 

Text manipulation is a daily task in DevOps. These commands are your Swiss Army knife:

- `cat [file]`: Displays the entire contents of a file
- `less [file]`: Views file contents page by page with navigation
- `nano [file]`: User-friendly text editor for quick modifications
- `vi [file]`: Advanced text editor with powerful features
- `grep [pattern] [file]`: Searches for text patterns within files
- `sed 's/old/new/g' [file]`: Stream editor for text transformation
- `awk '{print $1}' [file]`: Pattern scanning and processing language
- `sort [file]`: Sorts lines in a text file
- `cut -d':' -f1 [file]`: Extracts specific columns from text
- `diff [file1] [file2]`: Compares files line by line

## 3. Networking 

Network troubleshooting and management are crucial in modern infrastructure:

- `ifconfig`: Displays network interface configuration
- `ip a`: Shows IP addresses and network interfaces
- `ping [host]`: Tests network connectivity to a host
- `traceroute [host]`: Traces the network path to a host
- `wget [url]`: Downloads files from the web
- `curl [url]`: Transfers data from or to a server
- `netstat -tulnp`: Shows network connections and listening ports
- `ssh [user@host]`: Securely connects to remote servers

## 4. System Monitoring & Processes 

Keeping an eye on system resources is essential for performance:

- `top`: Real-time system monitoring and process management
- `htop`: Enhanced version of top with better visualization
- `ps aux`: Lists all running processes
- `kill [PID]`: Terminates a specific process
- `killall [name]`: Terminates all processes with a given name
- `jobs`: Lists background jobs
- `bg`: Continues a stopped job in the background
- `fg`: Brings a background job to the foreground
- `uptime`: Shows system uptime and load averages

## 5. Permission Management 

Security is paramount in system administration:

- `chmod [permissions] [file]`: Changes file permissions
- `chown [user]:[group] [file]`: Changes file owner and group
- `umask`: Sets default file permissions
- `ls -l`: Lists files with detailed permissions
- `sudo [command]`: Executes commands with superuser privileges
- `passwd [user]`: Changes user password

## 6. Storage & Disk Management 

Managing storage resources effectively is crucial for system health:

- `df -h`: Shows disk space usage in human-readable format
- `du -sh [dir]`: Displays directory size in human-readable format
- `mount [device] [dir]`: Mounts a filesystem
- `umount [dir/device]`: Unmounts a filesystem

### Advanced Command Combinations Using Pipes

Pipes (`|`) in Linux allow you to combine multiple commands, creating powerful one-liners for troubleshooting. Here are practical examples:

### 1. Process and Resource Analysis
```bash
# Find top 5 CPU-consuming processes with their full command line
ps aux --sort=-%cpu | head -n 6 | awk '{print $2, $3, $11}'

# Monitor memory usage of specific process
ps aux | grep nginx | awk '{print $2, $4, $11}' | sort -k2 -nr

# Find processes using more than 1GB of memory
ps aux | awk '$6 > 1024000 {print $2, $6/1024, $11}' | sort -k2 -nr
```

**Command Explanation:**
- `ps aux`: Lists all processes
- `awk`: Processes and filters text
- `sort -k2 -nr`: Sorts by second column numerically in reverse order

### 2. Log Analysis
```bash
# Find most frequent error messages in last hour
grep "ERROR" /var/log/syslog | grep "$(date -d '1 hour ago' '+%b %d %H')" | sort | uniq -c | sort -nr

# Monitor log file in real-time with filtering
tail -f /var/log/nginx/access.log | grep "404" | awk '{print $1, $7, $9}'

# Find unique IP addresses accessing a specific URL
grep "/api/v1/users" /var/log/nginx/access.log | awk '{print $1}' | sort | uniq -c | sort -nr
```

**Command Explanation:**
- `tail -f`: Follows log file in real-time
- `uniq -c`: Counts unique occurrences
- `date -d`: Formats date for filtering

### 3. Disk Space Management
```bash
# Find and sort largest directories
du -h --max-depth=1 /var | sort -hr | head -n 10

# Find files modified in last 24 hours larger than 100MB
find / -type f -mtime -1 -size +100M -exec ls -lh {} \; | sort -k5 -hr

# Clean up old log files
find /var/log -type f -name "*.log" -mtime +30 -exec rm {} \;
```

**Command Explanation:**
- `du -h`: Disk usage in human-readable format
- `find -mtime`: Files modified within time period
- `-exec`: Executes command on found files

### 4. Network Troubleshooting
```bash
# Find all established connections with process names
netstat -tulpn | grep ESTABLISHED | awk '{print $4, $7}' | sort

# Monitor network traffic by port
tcpdump -i any -n | awk '{print $3}' | cut -d. -f5 | sort | uniq -c | sort -nr

# Check open ports with service names
netstat -tulpn | awk '{print $4, $7}' | grep LISTEN | sort
```

**Command Explanation:**
- `netstat -tulpn`: Shows network connections
- `tcpdump`: Captures network packets
- `cut -d. -f5`: Extracts port numbers

### 5. System Performance
```bash
# Monitor CPU usage by process with custom formatting
top -b -n 1 | grep -A 10 "PID USER" | awk '{print $1, $2, $9, $10, $11}'

# Check system load with process count
uptime | awk '{print $8, $9, $10}' && ps aux | wc -l

# Monitor disk I/O by process
iotop -b -n 1 | head -n 10 | awk '{print $1, $2, $3, $4}'
```

**Command Explanation:**
- `top -b`: Batch mode for scripting
- `iotop`: Shows I/O usage by process
- `wc -l`: Counts lines

### 6. Security Analysis
```bash
# Find failed login attempts with IP addresses
grep "Failed password" /var/log/auth.log | awk '{print $11}' | sort | uniq -c | sort -nr

# Check for suspicious processes with network connections
ps aux | grep -i "suspicious" | awk '{print $2}' | xargs -I {} netstat -tulpn | grep {}

# Monitor file changes in critical directories
find /etc -type f -mtime -1 -exec ls -lh {} \; | sort -k6,7
```

**Command Explanation:**
- `xargs`: Converts input into command arguments
- `grep -i`: Case-insensitive search
- `-mtime -1`: Files modified in last 24 hours

### 7. Service Health Checks
```bash
# Check service status with custom formatting
systemctl list-units --type=service --state=running | awk '{print $1, $2}' | sort

# Monitor service logs with error filtering
journalctl -u nginx -f | grep -i "error" | awk '{print $1, $2, $3, $5}'

# Check service dependencies with status
systemctl list-dependencies nginx | grep -v "‚óè" | awk '{print $1}' | xargs systemctl status
```

**Command Explanation:**
- `systemctl list-units`: Lists system services
- `journalctl -f`: Follows journal logs
- `grep -v`: Excludes matching lines

### Best Practices for Using Pipes
1. **Keep it Readable**
   - Use line breaks for complex commands
   - Add comments for clarity
   - Use meaningful variable names in scripts

2. **Error Handling**
   - Add error checking
   - Use `set -e` in scripts
   - Implement proper logging

3. **Performance**
   - Limit output with `head` or `tail`
   - Use efficient sorting
   - Avoid unnecessary processing

4. **Security**
   - Sanitize input
   - Use proper permissions
   - Avoid sensitive data exposure

Remember to test these commands in a safe environment before using them in production. Some commands may require root privileges or specific permissions to execute properly.

*What's your favorite Linux command or combination? Share your experiences in the comments below!*
